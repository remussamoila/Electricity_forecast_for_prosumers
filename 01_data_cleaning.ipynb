# 01_data_cleaning.ipynb

# Step 1: Extract and Load Weather Data from ECA&D Archive

import zipfile
import os
import pandas as pd
from glob import glob
from io import StringIO

# Define paths
zip_path = "../data/ECA_blended_custom.zip"
extract_path = "../data/eca_extracted"

# Extract the ZIP file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Function to load a single station file
def load_station_file(filepath):
    with open(filepath, 'r') as f:
        lines = f.readlines()
    header_index = next(i for i, line in enumerate(lines) if line.strip().startswith("SOUID"))
    data_lines = lines[header_index + 1:]
    data_str = ''.join(data_lines)
    df = pd.read_csv(StringIO(data_str), skipinitialspace=True)
    staid = os.path.basename(filepath).split("STAID")[1].split(".")[0]
    df["STAID"] = int(staid)
    return df

# Load and concatenate all station data
station_files = glob(os.path.join(extract_path, "FG_STAID*.txt"))
all_data = pd.concat([load_station_file(f) for f in station_files], ignore_index=True)

# Preview data
print(all_data.head())
print(all_data.info())

# Replace missing values (-9999) with NaN and scale FG (0.1 m/s -> m/s)
all_data['FG'] = all_data['FG'].replace(-9999, pd.NA) / 10.0

# Convert DATE column to datetime format
all_data['DATE'] = pd.to_datetime(all_data['DATE'], format='%Y%m%d')

# Optional: Keep only valid quality codes (Q_FG == 0)
all_data = all_data[all_data['Q_FG'] == 0]

# Save cleaned dataset for future use
all_data.to_csv("../data/cleaned_wind_speed_all_stations.csv", index=False)

print("\nCleaned dataset saved to: ../data/cleaned_wind_speed_all_stations.csv")
